{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Malware Analysis Using Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this implementation, we will be leveraging the Nvidia Malconv Architecture [1] to build the model for predicting the Malware.\n",
    "\n",
    "<img src=\"Malconv-arc.png\" alt=\"Malconv Architecture\" height=\"300\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Importing required libraries\n",
    "import re\n",
    "import collections\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import binascii\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras.utils import to_categorical\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-01 11:18:25.379445\n"
     ]
    }
   ],
   "source": [
    "print (datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Engineering\n",
    "We will clean the byte sequences for any unknown characters and do the embedding by converting the input to a numerical format - each byte into an eight dimensional vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input files Paths\n",
    "TrainLabelspath = \"/mnt/disks/MLProject/data/r_TrainLabels.csv\"\n",
    "TestLabelspath = \"/mnt/disks/MLProject/data/r_Testlabels.csv\" \n",
    "\n",
    "TraindatasetPath = \"/mnt/disks/MLProject/data/r_train_dataset/\"\n",
    "TestdatasetPath = \"/mnt/disks/MLProject/data/r_test_dataset/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Method for Cleaning the bytes\n",
    "def cleanByteSequence(byteSequence):\n",
    "    dataStr = str(byteSequence)\n",
    "    dataStr = dataStr[2:]\n",
    "    dataStr = dataStr.replace(\"\\\\r\\\\n\", \" \")\n",
    "    dataStr2 = re.sub(r'\\b\\w{8}\\b','',dataStr)\n",
    "    dataStr3 = re.sub(r'\\s+',\" \", dataStr2)\n",
    "    return dataStr3\n",
    "\n",
    "def readFile(filePath):\n",
    "    with open(filePath, \"rb\") as binary_file:\n",
    "        data = binary_file.read()\n",
    "        return data\n",
    "\n",
    "#Method of Embedding bytes\n",
    "def embedByte(hex_string):\n",
    "    scale = 16\n",
    "    num_of_bits = 8\n",
    "    if(hex_string[0] ==\"?\"):\n",
    "        hex_string = \"00\"\n",
    "    if(hex_string[1] == \"?\"):\n",
    "        hex_string[1] = \"00\"\n",
    "        \n",
    "    binary_string = bin(int(hex_string, scale)) [2:].zfill(num_of_bits)\n",
    "    vec = np.zeros(8)\n",
    "    for i in range(8):\n",
    "        if(binary_string[i]==\"1\"):\n",
    "            vec[i]=float(1)/16\n",
    "        else:\n",
    "            vec[i]=-float(1)/16\n",
    "            \n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10100110\n",
      "[ 0.0625 -0.0625  0.0625 -0.0625 -0.0625  0.0625  0.0625 -0.0625]\n"
     ]
    }
   ],
   "source": [
    "#Embedding - Converting the input to a numerical format.\n",
    "#Embed each byte into a eight dimensional vector.\n",
    "# 1 -> 1/16 and 0 -> -1/16\n",
    "hex_string = \"A6\"\n",
    "scale = 16\n",
    "num_of_bits = 8\n",
    "binary_string = bin(int(hex_string, scale)) [2:].zfill(num_of_bits)\n",
    "print(binary_string)\n",
    "print(embedByte(hex_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-01 11:18:25.899135\n"
     ]
    }
   ],
   "source": [
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = [f for f in listdir(TraindatasetPath) if isfile(join(TraindatasetPath, f))]\n",
    "data = pd.read_csv(TrainLabelspath)\n",
    "targetDict = data.set_index('Id').T.to_dict('records')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading Samples\n",
    "max_size = 30000      #Number of bytes to read per sample\n",
    "num_samples = len(samples)\n",
    "Train_X = np.zeros((num_samples, 8, max_size))\n",
    "Train_Y = np.zeros(num_samples)\n",
    "fileNum = 0\n",
    "for file in samples:\n",
    "    filePath = join(TraindatasetPath, file)\n",
    "    sampleByteSequence = readFile(filePath)\n",
    "    #print(fileNum)\n",
    "    cleanedByteSequence = cleanByteSequence(sampleByteSequence)\n",
    "    splitByteSequence = cleanedByteSequence.strip().split(\" \")\n",
    "    Train_Y[fileNum] = targetDict[file.split(\".\")[0]]       #Stores the labels\n",
    "    \n",
    "    for i in range(min(max_size, len(splitByteSequence))):\n",
    "        Train_X[fileNum,:,i] = embedByte(splitByteSequence[i]) #All embeded data \n",
    "    fileNum += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-01 12:45:10.420769\n"
     ]
    }
   ],
   "source": [
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]]\n",
      "(6520, 9)\n"
     ]
    }
   ],
   "source": [
    "#Convert lables to categorical form\n",
    "Train_Y_one_hot = to_categorical(Train_Y-1)\n",
    "print(Train_Y_one_hot)\n",
    "print(Train_Y_one_hot.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the Model\n",
    "Using Keras functional API, we will take two convolutions - conv1 and conv2 and then activate one of the convolutions, say conv2, sigmoid. We then multiply the Activated convolution and  non activated convolution and activate the final result - relu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 9\n",
    "from keras import optimizers\n",
    "from keras import Input\n",
    "from keras.layers import Conv1D\n",
    "from keras.layers import Activation \n",
    "from keras.layers import multiply\n",
    "from keras.layers import GlobalMaxPool1D\n",
    "from keras.layers import Dense\n",
    "from keras import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(8,max_size)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1 = Conv1D(kernel_size=(128), filters=32, strides=(128), padding='same')(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv2 = Conv1D(kernel_size=(128), filters=32, strides=(128), padding='same')(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Activation('sigmoid', name='sigmoid')(conv2)  #Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mul = multiply([conv1, a]) #Multiplying Activated one and Non-Activated one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Activation('relu', name='relu')(mul) #Activating the result - mul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = GlobalMaxPool1D()(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = Dense(16)(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = Dense(num_classes, activation = 'sigmoid') (d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=inputs, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model summary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 8, 30000)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 1, 32)        122880032   input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 1, 32)        122880032   input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sigmoid (Activation)            (None, 1, 32)        0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 1, 32)        0           conv1d_1[0][0]                   \n",
      "                                                                 sigmoid[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "relu (Activation)               (None, 1, 32)        0           multiply_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_1 (GlobalM (None, 32)           0           relu[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 16)           528         global_max_pooling1d_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 9)            153         dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 245,760,745\n",
      "Trainable params: 245,760,745\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model with Train Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16   #Dividing the dataset into multiple batches\n",
    "num_batches = int(num_samples/batch_size)\n",
    "\n",
    "for batch_num in range(num_batches):\n",
    "    batch = Train_X[batch_num * batch_size:(batch_num+1)*batch_size]\n",
    "    model.train_on_batch(batch, Train_Y_one_hot[batch_num * batch_size:(batch_num+1)*batch_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(Train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.2068312e-01, 5.6424928e-01, 2.1557412e-01, ..., 1.1670318e-01,\n",
       "        2.1745884e-01, 7.0136219e-01],\n",
       "       [8.1635594e-02, 9.9390745e-04, 4.7683716e-07, ..., 4.0829182e-06,\n",
       "        1.2341142e-04, 1.4496446e-03],\n",
       "       [2.1457672e-06, 0.0000000e+00, 0.0000000e+00, ..., 0.0000000e+00,\n",
       "        4.1770387e-01, 1.4901161e-07],\n",
       "       ...,\n",
       "       [1.7415881e-03, 2.3207068e-04, 1.4215708e-05, ..., 1.5127659e-04,\n",
       "        5.6892633e-04, 6.1125910e-01],\n",
       "       [7.2476268e-04, 6.4472193e-01, 0.0000000e+00, ..., 8.9406967e-08,\n",
       "        2.0861626e-07, 5.5789948e-05],\n",
       "       [1.9618064e-02, 8.4722340e-03, 1.1920929e-07, ..., 1.1026859e-06,\n",
       "        3.7610531e-05, 5.0544739e-04]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_label = []\n",
    "for row in pred:\n",
    "    pred_label.append(np.argmax(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5. 0. 7. ... 8. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "Train_Y_np = np.asarray(Train_Y-1)\n",
    "print(Train_Y_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5,\n",
       " 0,\n",
       " 7,\n",
       " 6,\n",
       " 2,\n",
       " 8,\n",
       " 2,\n",
       " 1,\n",
       " 7,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 7,\n",
       " 8,\n",
       " 1,\n",
       " 1,\n",
       " 8,\n",
       " 2,\n",
       " 7,\n",
       " 0,\n",
       " 7,\n",
       " 0,\n",
       " 7,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 8,\n",
       " 1,\n",
       " 8,\n",
       " 2,\n",
       " 8,\n",
       " 7,\n",
       " 2,\n",
       " 7,\n",
       " 2,\n",
       " 0,\n",
       " 6,\n",
       " 1,\n",
       " 2,\n",
       " 8,\n",
       " 7,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 8,\n",
       " 7,\n",
       " 7,\n",
       " 0,\n",
       " 6,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 8,\n",
       " 7,\n",
       " 7,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 7,\n",
       " 1,\n",
       " 5,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 8,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 8,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 8,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 7,\n",
       " 0,\n",
       " 8,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 8,\n",
       " 7,\n",
       " 8,\n",
       " 1,\n",
       " 1,\n",
       " 6,\n",
       " 2,\n",
       " 1,\n",
       " 8,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 8,\n",
       " 7,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 8,\n",
       " 2,\n",
       " 8,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 8,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 5,\n",
       " 7,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 8,\n",
       " 8,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 8,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 7,\n",
       " 8,\n",
       " 8,\n",
       " 0,\n",
       " 7,\n",
       " 0,\n",
       " 7,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 8,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 8,\n",
       " 7,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 7,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 8,\n",
       " 2,\n",
       " 5,\n",
       " 0,\n",
       " 7,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 7,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 5,\n",
       " 2,\n",
       " 8,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 6,\n",
       " 2,\n",
       " 0,\n",
       " 7,\n",
       " 8,\n",
       " 6,\n",
       " 1,\n",
       " 8,\n",
       " 6,\n",
       " 7,\n",
       " 2,\n",
       " 1,\n",
       " 7,\n",
       " 7,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 6,\n",
       " 5,\n",
       " 2,\n",
       " 8,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 7,\n",
       " 0,\n",
       " 7,\n",
       " 5,\n",
       " 7,\n",
       " 5,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 7,\n",
       " 0,\n",
       " 8,\n",
       " 2,\n",
       " 8,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 7,\n",
       " 1,\n",
       " 1,\n",
       " 8,\n",
       " 5,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 8,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 8,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 8,\n",
       " 5,\n",
       " 7,\n",
       " 5,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 5,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 8,\n",
       " 2,\n",
       " 7,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 8,\n",
       " 7,\n",
       " 1,\n",
       " 8,\n",
       " 8,\n",
       " 1,\n",
       " 8,\n",
       " 1,\n",
       " 1,\n",
       " 6,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 7,\n",
       " 6,\n",
       " 5,\n",
       " 2,\n",
       " 7,\n",
       " 7,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 8,\n",
       " 7,\n",
       " 7,\n",
       " 1,\n",
       " 1,\n",
       " 7,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 8,\n",
       " 1,\n",
       " 0,\n",
       " 7,\n",
       " 0,\n",
       " 7,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 8,\n",
       " 2,\n",
       " 1,\n",
       " 7,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 7,\n",
       " 8,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 8,\n",
       " 7,\n",
       " 6,\n",
       " 2,\n",
       " 7,\n",
       " 0,\n",
       " 8,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 7,\n",
       " 3,\n",
       " 8,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 7,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 5,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 6,\n",
       " 0,\n",
       " 8,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 5,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 6,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 5,\n",
       " 7,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 8,\n",
       " 5,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 7,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 7,\n",
       " 1,\n",
       " 5,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 7,\n",
       " 2,\n",
       " 1,\n",
       " 5,\n",
       " 2,\n",
       " 6,\n",
       " 0,\n",
       " 1,\n",
       " 5,\n",
       " 7,\n",
       " 6,\n",
       " 8,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 7,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 8,\n",
       " 0,\n",
       " 5,\n",
       " 2,\n",
       " 7,\n",
       " 7,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 8,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 8,\n",
       " 7,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 6,\n",
       " 2,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 8,\n",
       " 1,\n",
       " 1,\n",
       " 8,\n",
       " 5,\n",
       " 5,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 6,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 8,\n",
       " 1,\n",
       " 7,\n",
       " 0,\n",
       " 7,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 8,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 6,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 8,\n",
       " 1,\n",
       " 2,\n",
       " 7,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 6,\n",
       " 7,\n",
       " 1,\n",
       " 8,\n",
       " 0,\n",
       " 5,\n",
       " 8,\n",
       " 2,\n",
       " 7,\n",
       " 8,\n",
       " 2,\n",
       " 7,\n",
       " 7,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 8,\n",
       " 5,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 7,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 8,\n",
       " 8,\n",
       " 2,\n",
       " 8,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 6,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 7,\n",
       " 5,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 8,\n",
       " 5,\n",
       " 2,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 8,\n",
       " 1,\n",
       " 7,\n",
       " 6,\n",
       " 0,\n",
       " 5,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 8,\n",
       " 1,\n",
       " 1,\n",
       " 7,\n",
       " 2,\n",
       " 5,\n",
       " 5,\n",
       " 7,\n",
       " 0,\n",
       " 5,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 7,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 8,\n",
       " 8,\n",
       " 0,\n",
       " 6,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 7,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 8,\n",
       " 2,\n",
       " 1,\n",
       " 8,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 7,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 8,\n",
       " 1,\n",
       " 7,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 7,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 7,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 7,\n",
       " 1,\n",
       " 8,\n",
       " 0,\n",
       " 6,\n",
       " 8,\n",
       " 2,\n",
       " 1,\n",
       " 7,\n",
       " 2,\n",
       " 2,\n",
       " 8,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 8,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 8,\n",
       " 8,\n",
       " 7,\n",
       " 8,\n",
       " 7,\n",
       " 0,\n",
       " 7,\n",
       " 1,\n",
       " 1,\n",
       " 7,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 7,\n",
       " 5,\n",
       " 0,\n",
       " 5,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 8,\n",
       " 2,\n",
       " 8,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 7,\n",
       " 0,\n",
       " 2,\n",
       " 8,\n",
       " 7,\n",
       " 0,\n",
       " 1,\n",
       " 6,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 7,\n",
       " 0,\n",
       " 8,\n",
       " 7,\n",
       " 7,\n",
       " 8,\n",
       " 1,\n",
       " 3,\n",
       " 5,\n",
       " 8,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 6,\n",
       " 2,\n",
       " 0,\n",
       " 8,\n",
       " 1,\n",
       " 1,\n",
       " 8,\n",
       " 5,\n",
       " 5,\n",
       " 2,\n",
       " 8,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 7,\n",
       " 8,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 8,\n",
       " 7,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 7,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 8,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 8,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 5,\n",
       " 8,\n",
       " 7,\n",
       " 2,\n",
       " 7,\n",
       " 3,\n",
       " 6,\n",
       " 0,\n",
       " 7,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 6,\n",
       " 7,\n",
       " 0,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 5,\n",
       " 7,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 8,\n",
       " 0,\n",
       " 8,\n",
       " 2,\n",
       " 2,\n",
       " 7,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 7,\n",
       " 7,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 8,\n",
       " 0,\n",
       " 7,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 7,\n",
       " 7,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 7,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 8,\n",
       " 8,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 8,\n",
       " 7,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 7,\n",
       " 8,\n",
       " 7,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 2,\n",
       " ...]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'96.74846625766871%'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(sum(pred_label == Train_Y_np)/len(Train_Y_np)*100)+\"%\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-01 13:14:47.307690\n"
     ]
    }
   ],
   "source": [
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "testSamples = [f for f in listdir(TestdatasetPath) if isfile(join(TestdatasetPath, f))]\n",
    "data_test = pd.read_csv(TestLabelspath)\n",
    "targetDict_test = data_test.set_index('Id').T.to_dict('records')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_X = np.zeros((num_samples, 8, max_size))\n",
    "Test_Y = np.zeros(num_samples)\n",
    "fileNum = 0\n",
    "\n",
    "for file in testSamples:\n",
    "    filePath = join(TestdatasetPath, file)\n",
    "    sampleByteSequence = readFile(filePath)\n",
    "    #print(fileNum)\n",
    "    cleanedByteSequence = cleanByteSequence(sampleByteSequence)\n",
    "    splitByteSequence = cleanedByteSequence.strip().split(\" \")\n",
    "    Test_Y[fileNum] = targetDict_test[file.split(\".\")[0]]\n",
    "    for i in range(min(max_size, len(splitByteSequence))):\n",
    "        Test_X[fileNum,:,i] = embedByte(splitByteSequence[i])\n",
    "    fileNum += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_Y_np = np.asarray(Test_Y-1)\n",
    "Test_Y_pred = model.predict(Test_X)\n",
    "Test_Y_pred_label = []\n",
    "for row in Test_Y_pred:\n",
    "    Test_Y_pred_label.append(np.argmax(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'58.11349693251534%'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(sum(Test_Y_pred_label == Test_Y_np)/len(Test_Y_np)*100)+\"%\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-01 14:11:40.916807\n"
     ]
    }
   ],
   "source": [
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict on Test Dataset\n",
    "Running the model to predict the classification on the \"given\" Test dataset, which don't have labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o_TestLabelspath = \"/mnt/disks/MLProject/data/testLabels.csv\" \n",
    "o_TestdatasetPath = \"/mnt/disks/MLProject/data/test_dataset\"\n",
    "\n",
    "testSamples = [f for f in listdir(o_TestdatasetPath) if isfile(join(o_TestdatasetPath, f))]\n",
    "data_test = pd.read_csv(o_TestLabelspath)\n",
    "targetDict_test_o = data_test.set_index('Id').T.to_dict('records')[0]\n",
    "\n",
    "testSamples = testSamples[:5000]\n",
    "\n",
    "Testo_X = np.zeros((num_samples, 8, max_size))\n",
    "Testo_Y = np.zeros(num_samples)\n",
    "fileNum = 0\n",
    "\n",
    "for file in testSamples:\n",
    "    filePath = join(o_TestdatasetPath, file)\n",
    "    sampleByteSequence = readFile(filePath)\n",
    "    cleanedByteSequence = cleanByteSequence(sampleByteSequence)\n",
    "    splitByteSequence = cleanedByteSequence.strip().split(\" \")\n",
    "    Testo_Y[fileNum] = targetDict_test_o[file.split(\".\")[0]]\n",
    "    for i in range(min(max_size, len(splitByteSequence))):\n",
    "        Testo_X[fileNum,:,i] = embedByte(splitByteSequence[i])\n",
    "    fileNum += 1\n",
    "\n",
    "Testo_Y_np = np.asarray(Testo_Y-1)\n",
    "Testo_Y_pred = model.predict(Testo_X)\n",
    "Testo_Y_pred_label = []\n",
    "\n",
    "for row in Testo_Y_pred:\n",
    "    Testo_Y_pred_label.append(np.argmax(row))\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Testo_Y_pred_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References:  \n",
    "[1] Raff, E., Barker, J., Sylvester, J., Brandon, R., Catanzaro, B., & Nicholas, C.K. (2017). Malware Detection by Eating a Whole EXE. ArXiv, abs/1710.09435.  \n",
    "[2] Dataset: https://www.kaggle.com/c/malware-classification/data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
