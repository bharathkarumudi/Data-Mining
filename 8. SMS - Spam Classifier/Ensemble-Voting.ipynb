{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q6\n",
    "#### Boosting, Bagging, and Stackingâ€” Ensemble Methods with sklearn and mlens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0. Imports of libraries that allow the Python code to work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[MLENS] backend: threading\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/bharathkarumudi/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# from pydataset import data\n",
    "from sklearn.preprocessing import normalize, StandardScaler\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.ensemble import BaggingClassifier, ExtraTreesClassifier, RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import RidgeClassifier, LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.pyplot as plt\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "import matplotlib.gridspec as gridspec\n",
    "import itertools\n",
    "from mlxtend.classifier import EnsembleVoteClassifier\n",
    "import warnings\n",
    "from xgboost import XGBClassifier, plot_importance\n",
    "from mlens.ensemble import SuperLearner\n",
    "from sklearn.metrics import accuracy_score\n",
    "from itertools import combinations\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import nltk\n",
    "from nltk import word_tokenize        \n",
    "from nltk.stem import WordNetLemmatizer \n",
    "nltk.download('wordnet')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Obtaining and cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2 Unnamed: 2  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4  \n",
       "0        NaN        NaN  \n",
       "1        NaN        NaN  \n",
       "2        NaN        NaN  \n",
       "3        NaN        NaN  \n",
       "4        NaN        NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat = pd.read_csv(\"data/spam.csv\", encoding='latin-1')\n",
    "dat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's start our cleaning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>sms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   y                                                sms\n",
       "0  0  Go until jurong point, crazy.. Available only ...\n",
       "1  0                      Ok lar... Joking wif u oni...\n",
       "2  1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3  0  U dun say so early hor... U c already then say...\n",
       "4  0  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat = dat.loc[:, ['v1', 'v2']]\n",
    "dat.rename(columns={'v1': 'y', 'v2': 'sms'}, inplace=True)\n",
    "dat.y = dat.y.replace({'ham': 0, 'spam': 1})\n",
    "dat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Onehot Encoding\n",
    "Removing the stop words which do not add value, create ngrams and also filter the words that appears in almost all or very less apperance.\n",
    "\n",
    "Some words in the English language, while necessary, don't contribute much to the meaning of a phrase. These words, such as \"when\", \"had\", \"those\" or \"before\", are called stop words and should be filtered out.\n",
    "\n",
    "We can tokenize individual terms and generate what's called a bag of words model. You may notice this model has a glaring pitfall: it fails to capture the innate structure of human language. Under this model, the following sentences have the same feature vector although they convey dramatically different meanings.\n",
    "\n",
    "Does steak taste delicious?\n",
    "Steak does taste delicious.\n",
    "\n",
    "Alternatively, we can tokenize every sequence of n terms called n-grams. For example, tokenizing adjacent pairs of words yields bigrams. The n\n",
    "\n",
    "-gram model preserves word order and can potentially capture more information than the bag of words model.\n",
    "\n",
    "To get the best of both worlds, let's tokenize unigrams and bigrams. As an example, unigrams and bigrams for \"The quick brown fox\" are \"The\", \"quick\", \"brown\", \"fox\", \"The quick\", \"quick brown\" and \"brown fox\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LemmaTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "    def __call__(self, articles):\n",
    "        return [self.wnl.lemmatize(t) for t in word_tokenize(articles)]\n",
    "\n",
    "\n",
    "def preprocess_txt(raw_text):\n",
    "    \n",
    "    processed = raw_text.str.replace(r'\\b[\\w\\-.]+?@\\w+?\\.\\w{2,4}\\b', 'emailaddr')\n",
    "    processed = processed.str.replace(r'(http[s]?\\S+)|(\\w+\\.[A-Za-z]{2,4}\\S*)', 'httpaddr')\n",
    "    processed = processed.str.replace(r'Â£|\\$', 'moneysymb')    \n",
    "    processed = processed.str.replace(r'\\b(\\+\\d{1,2}\\s)?\\d?[\\-(.]?\\d{3}\\)?[\\s.-]?\\d{3}[\\s.-]?\\d{4}\\b', 'phonenumbr')\n",
    "    processed = processed.str.replace(r'\\d+(\\.\\d+)?', 'numbr')\n",
    "\n",
    "    processed = processed.str.replace(r'[^\\w\\d\\s]', ' ')\n",
    "    processed = processed.str.replace(r'\\s+', ' ')\n",
    "    processed = processed.str.replace(r'^\\s+|\\s+?$', '')\n",
    "\n",
    "    processed = processed.str.lower()\n",
    "    \n",
    "    return processed\n",
    "processed = preprocess_txt(dat.sms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encode words\n",
    "vec = TfidfVectorizer(tokenizer=LemmaTokenizer(),\n",
    "                      stop_words='english', # Remove stop words like a, an, the, etc that do not add much value.\n",
    "                      ngram_range=(1, 2),   # create unigrams and bigrams.\n",
    "                      min_df=0.01,          # filter words that appear in less than 1% of records\n",
    "                      max_df=0.99)          # filter words that appear in more than 99% of records.\n",
    "\n",
    "X = vec.fit_transform(processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_len = dat.sms.apply(len).values\n",
    "message_len = message_len / max(message_len)\n",
    "\n",
    "message_n_words = np.array([len(x) for x in dat.sms.str.split()])\n",
    "message_n_words = message_n_words / max(message_n_words)\n",
    "\n",
    "all_caps_freq = np.array([sum(1 for c in message if c.isupper()) for message in dat.sms]) / message_len\n",
    "\n",
    "avg_word_len = []\n",
    "for message in dat.sms.str.split():\n",
    "    message_word_lens = []\n",
    "    for word in message:\n",
    "        message_word_lens.append(len(word))\n",
    "    avg_word_len.append(np.mean(message_word_lens))\n",
    "avg_word_len = np.array(avg_word_len)\n",
    "\n",
    "\n",
    "corr_coef, p = pearsonr(message_len, message_n_words) # highly correlated\n",
    "\n",
    "\n",
    "X = np.column_stack((X.todense(), message_n_words, all_caps_freq, avg_word_len))\n",
    "X_column_names = vec.get_feature_names() + ['message_n_words', 'all_caps_freq', 'avg_word_len']\n",
    "X = pd.DataFrame(X, columns=X_column_names)\n",
    "\n",
    "y = dat.y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Split into training and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get index of message_n_words\n",
    "message_n_words_index = [i for i, name in enumerate(X) if name == 'message_n_words']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=1234, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_n_words_train = X_train['message_n_words']\n",
    "message_n_words_test = X_test['message_n_words']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Create Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of: 0.982, std: (+/-) 0.004 [RandomForestClassifier]\n",
      "Mean of: 0.888, std: (+/-) 0.006 [Bagging RandomForestClassifier]\n",
      "\n",
      "Mean of: 0.982, std: (+/-) 0.004 [ExtraTreesClassifier]\n",
      "Mean of: 0.890, std: (+/-) 0.007 [Bagging ExtraTreesClassifier]\n",
      "\n",
      "Mean of: 0.916, std: (+/-) 0.012 [KNeighborsClassifier]\n",
      "Mean of: 0.888, std: (+/-) 0.007 [Bagging KNeighborsClassifier]\n",
      "\n",
      "Mean of: 0.891, std: (+/-) 0.017 [SVC]\n",
      "Mean of: 0.866, std: (+/-) 0.001 [Bagging SVC]\n",
      "\n",
      "Mean of: 0.979, std: (+/-) 0.005 [RidgeClassifier]\n",
      "Mean of: 0.866, std: (+/-) 0.001 [Bagging RidgeClassifier]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "seed = 1234\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Create classifiers\n",
    "rf = RandomForestClassifier()\n",
    "et = ExtraTreesClassifier()\n",
    "knn = KNeighborsClassifier()\n",
    "svc = SVC()\n",
    "rg = RidgeClassifier()\n",
    "\n",
    "clf_array = [rf, et, knn, svc, rg]\n",
    "\n",
    "for clf in clf_array:\n",
    "    vanilla_scores = cross_val_score(clf, X_train, y_train, cv=10, n_jobs=-1)\n",
    "    bagging_clf = BaggingClassifier(clf, max_samples=0.4, max_features=10, random_state=seed)\n",
    "    bagging_scores = cross_val_score(bagging_clf, X_train, y_train, cv=10, n_jobs=-1)\n",
    "    \n",
    "    print(\"Mean of: {1:.3f}, std: (+/-) {2:.3f} [{0}]\".format(clf.__class__.__name__, \n",
    "                                                              vanilla_scores.mean(), vanilla_scores.std()))\n",
    "    print(\"Mean of: {1:.3f}, std: (+/-) {2:.3f} [Bagging {0}]\\n\".format(clf.__class__.__name__, \n",
    "                                                                        bagging_scores.mean(), bagging_scores.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.983, std: (+/-) 0.004 [Random Forest]\n",
      "Mean: 0.983, std: (+/-) 0.004 [Extra Trees]\n",
      "Mean: 0.916, std: (+/-) 0.012 [KNeighbors]\n",
      "Mean: 0.891, std: (+/-) 0.017 [SVC]\n",
      "Mean: 0.979, std: (+/-) 0.005 [Ridge Classifier]\n",
      "Mean: 0.984, std: (+/-) 0.004 [Ensemble]\n"
     ]
    }
   ],
   "source": [
    "# Set up voting\n",
    "eclf = VotingClassifier(estimators=[('Random Forests', rf), ('Extra Trees', et), \n",
    "                                    ('KNeighbors', knn), ('SVC', svc), ('Ridge Classifier', rg)], voting='hard')\n",
    "\n",
    "for clf, label in zip([rf, et, knn, svc, rg, eclf], ['Random Forest', 'Extra Trees', \n",
    "                                                     'KNeighbors', 'SVC', 'Ridge Classifier', 'Ensemble']):\n",
    "    scores = cross_val_score(clf, X_train, y_train, cv=10, scoring='accuracy')\n",
    "    print(\"Mean: {0:.3f}, std: (+/-) {1:.3f} [{2}]\".format(scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ensemble voting for bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.886, std: (+/-) 0.005 [Bagging Random Forest]\n",
      "Mean: 0.888, std: (+/-) 0.004 [Bagging Extra Trees]\n",
      "Mean: 0.886, std: (+/-) 0.008 [Bagging KNeighbors]\n",
      "Mean: 0.866, std: (+/-) 0.001 [Bagging SVC]\n",
      "Mean: 0.866, std: (+/-) 0.001 [Bagging Ridge Classifier]\n",
      "Mean: 0.876, std: (+/-) 0.005 [Bagging Ensemble]\n"
     ]
    }
   ],
   "source": [
    "# Set up ensemble voting for bagging\n",
    "\n",
    "\n",
    "ebclf_array = [BaggingClassifier(clf, max_samples=0.25, max_features=10, random_state=seed) for clf in clf_array]\n",
    "\n",
    "# ebclf_array = []\n",
    "# for clf in clf_array:\n",
    "#     ebclf_array.append(\n",
    "#         BaggingClassifier(clf, max_samples=0.25, max_features=10, random_state=seed)\n",
    "#     )\n",
    "\n",
    "v_eclf = VotingClassifier(\n",
    "    estimators=list(zip(\n",
    "        [\n",
    "            \"Bagging Random Forest\",\n",
    "            \"Bagging Extra Trees\",\n",
    "            \"Bagging KNeighbors\",\n",
    "            \"Bagging SVC\",\n",
    "            \"Bagging Ridge Classifier\",\n",
    "            \"Bagging Ensemble\",\n",
    "        ],\n",
    "        ebclf_array,\n",
    "    )),\n",
    "    voting=\"hard\",\n",
    ")\n",
    "\n",
    "ebclf_array.append(v_eclf)\n",
    "\n",
    "for clf, label in zip(\n",
    "    ebclf_array,\n",
    "    [\n",
    "        \"Bagging Random Forest\",\n",
    "        \"Bagging Extra Trees\",\n",
    "        \"Bagging KNeighbors\",\n",
    "        \"Bagging SVC\",\n",
    "        \"Bagging Ridge Classifier\",\n",
    "        \"Bagging Ensemble\",\n",
    "    ],\n",
    "):\n",
    "    scores = cross_val_score(clf, X_train, y_train, cv=10, scoring=\"accuracy\")\n",
    "    print(\n",
    "        \"Mean: {0:.3f}, std: (+/-) {1:.3f} [{2}]\".format(\n",
    "            scores.mean(), scores.std(), label\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boosting classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.982, std: (+/-) 0.005 [Ada Boost]\n",
      "Mean: 0.985, std: (+/-) 0.005 [Grad Boost]\n",
      "Mean: 0.983, std: (+/-) 0.006 [XG Boost]\n",
      "Mean: 0.985, std: (+/-) 0.006 [Ensemble]\n"
     ]
    }
   ],
   "source": [
    "# Create boosting classifiers\n",
    "ada_boost = AdaBoostClassifier()\n",
    "grad_boost = GradientBoostingClassifier()\n",
    "xgb_boost = XGBClassifier()\n",
    "\n",
    "boost_array = [ada_boost, grad_boost, xgb_boost]\n",
    "\n",
    "eclf = EnsembleVoteClassifier(clfs=[ada_boost, grad_boost, xgb_boost], voting='hard')\n",
    "\n",
    "labels = ['Ada Boost', 'Grad Boost', 'XG Boost', 'Ensemble']\n",
    "\n",
    "for clf, label in zip([ada_boost, grad_boost, xgb_boost, eclf], labels):\n",
    "    scores = cross_val_score(clf, X_train, y_train, cv=10, scoring='accuracy')\n",
    "    print(\"Mean: {0:.3f}, std: (+/-) {1:.3f} [{2}]\".format(scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fitting 2 layers\n",
      "Processing layer-1             done | 00:00:04\n",
      "Processing layer-2             done | 00:00:00\n",
      "Fit complete                        | 00:00:04\n",
      "\n",
      "Predicting 2 layers\n",
      "Processing layer-1             done | 00:00:00\n",
      "Processing layer-2             done | 00:00:00\n",
      "Predict complete                    | 00:00:00\n",
      "Fit data:\n",
      "                                   score-m  score-s  ft-m  ft-s  pt-m  pt-s\n",
      "layer-1  extratreesclassifier         0.98     0.00  0.68  0.14  0.02  0.02\n",
      "layer-1  kneighborsclassifier         0.92     0.02  0.08  0.05  0.35  0.08\n",
      "layer-1  randomforestclassifier       0.98     0.01  0.31  0.03  0.01  0.01\n",
      "layer-1  ridgeclassifier              0.98     0.01  0.05  0.01  0.00  0.00\n",
      "\n",
      "Accuracy score: 0.984\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "seed = 1075\n",
    "ensemble = SuperLearner(scorer = accuracy_score, \n",
    "                        random_state=seed, \n",
    "                        folds=10,\n",
    "                        verbose = 2)\n",
    "\n",
    "# Build the first layer\n",
    "ensemble.add([rf, et, knn, rg])\n",
    "# Attach the final meta estimator\n",
    "ensemble.add_meta(lr)\n",
    "\n",
    "ensemble.fit(X_train, y_train)\n",
    "preds = ensemble.predict(X_test)\n",
    "print(\"Fit data:\\n%r\" % ensemble.data)\n",
    "print(\"Accuracy score: {:.3f}\".format(accuracy_score(preds, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.981 ['Random Forest']\n",
      "Accuracy score: 0.980 ['Extra Trees']\n",
      "Accuracy score: 0.922 ['KNeighbors']\n",
      "Accuracy score: 0.880 ['SVC']\n",
      "Accuracy score: 0.976 ['Ridge Classifier']\n",
      "Accuracy score: 0.984 ['Random Forest', 'Extra Trees']\n",
      "Accuracy score: 0.982 ['Random Forest', 'KNeighbors']\n",
      "Accuracy score: 0.979 ['Random Forest', 'SVC']\n",
      "Accuracy score: 0.981 ['Random Forest', 'Ridge Classifier']\n",
      "Accuracy score: 0.978 ['Extra Trees', 'KNeighbors']\n",
      "Accuracy score: 0.977 ['Extra Trees', 'SVC']\n",
      "Accuracy score: 0.979 ['Extra Trees', 'Ridge Classifier']\n",
      "Accuracy score: 0.922 ['KNeighbors', 'SVC']\n",
      "Accuracy score: 0.976 ['KNeighbors', 'Ridge Classifier']\n",
      "Accuracy score: 0.976 ['SVC', 'Ridge Classifier']\n",
      "Accuracy score: 0.981 ['Random Forest', 'Extra Trees', 'KNeighbors']\n",
      "Accuracy score: 0.981 ['Random Forest', 'Extra Trees', 'SVC']\n",
      "Accuracy score: 0.978 ['Random Forest', 'Extra Trees', 'Ridge Classifier']\n",
      "Accuracy score: 0.978 ['Random Forest', 'KNeighbors', 'SVC']\n",
      "Accuracy score: 0.982 ['Random Forest', 'KNeighbors', 'Ridge Classifier']\n",
      "Accuracy score: 0.984 ['Random Forest', 'SVC', 'Ridge Classifier']\n",
      "Accuracy score: 0.981 ['Extra Trees', 'KNeighbors', 'SVC']\n",
      "Accuracy score: 0.985 ['Extra Trees', 'KNeighbors', 'Ridge Classifier']\n",
      "Accuracy score: 0.978 ['Extra Trees', 'SVC', 'Ridge Classifier']\n",
      "Accuracy score: 0.976 ['KNeighbors', 'SVC', 'Ridge Classifier']\n",
      "Accuracy score: 0.980 ['Random Forest', 'Extra Trees', 'KNeighbors', 'SVC']\n",
      "Accuracy score: 0.983 ['Random Forest', 'Extra Trees', 'KNeighbors', 'Ridge Classifier']\n",
      "Accuracy score: 0.982 ['Random Forest', 'Extra Trees', 'SVC', 'Ridge Classifier']\n",
      "Accuracy score: 0.982 ['Random Forest', 'KNeighbors', 'SVC', 'Ridge Classifier']\n",
      "Accuracy score: 0.982 ['Extra Trees', 'KNeighbors', 'SVC', 'Ridge Classifier']\n",
      "Accuracy score: 0.980 ['Random Forest', 'Extra Trees', 'KNeighbors', 'SVC', 'Ridge Classifier']\n",
      "\n",
      "Best stacking model is ['Extra Trees', 'KNeighbors', 'Ridge Classifier'] with accuracy of: 0.985\n"
     ]
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "names = ['Random Forest', 'Extra Trees', 'KNeighbors', 'SVC', 'Ridge Classifier']\n",
    "\n",
    "def zip_stacked_classifiers(*args):\n",
    "    to_zip = []\n",
    "    for arg in args:\n",
    "        combined_items = sum([list(map(list, combinations(arg, i))) for i in range(len(arg) + 1)], [])\n",
    "        combined_items = filter(lambda x: len(x) > 0, combined_items)\n",
    "        to_zip.append(combined_items)\n",
    "    \n",
    "    return zip(to_zip[0], to_zip[1])\n",
    "\n",
    "stacked_clf_list = zip_stacked_classifiers(clf_array, names)\n",
    "\n",
    "best_combination = [0.00, \"\"]\n",
    "\n",
    "for clf in stacked_clf_list:\n",
    "    \n",
    "    ensemble = SuperLearner(scorer = accuracy_score, \n",
    "                            random_state = seed, \n",
    "                            folds = 10)\n",
    "    ensemble.add(clf[0])\n",
    "    ensemble.add_meta(lr)\n",
    "    ensemble.fit(X_train, y_train)\n",
    "    preds = ensemble.predict(X_test)\n",
    "    accuracy = accuracy_score(preds, y_test)\n",
    "    \n",
    "    if accuracy > best_combination[0]:\n",
    "        best_combination[0] = accuracy\n",
    "        best_combination[1] = clf[1]\n",
    "    \n",
    "    print(\"Accuracy score: {:.3f} {}\".format(accuracy, clf[1]))\n",
    "\n",
    "print(\"\\nBest stacking model is {} with accuracy of: {:.3f}\".format(best_combination[1], best_combination[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References:\n",
    "[1] https://medium.com/@rrfd/boosting-bagging-and-stacking-ensemble-methods-with-sklearn-and-mlens-a455c0c982de  \n",
    "[2] Dataset: https://www.kaggle.com/uciml/sms-spam-collection-dataset/  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
